# Deploying InternLM2

支持部署运行 InternLM2-1.8B，InternLM2-7B 和 InternLM2-20B 两个模型。
模型使用 ModelScope 托管，也支持加载 OpenXLab 托管的模型。

资源使用参考
- InternLM2-1.B: A10 GPU, 10G 显存
- InternLM2-7B: A10 GPU, 24G 显存
- InternLM2-20B: A100 GPU, 80G 显存